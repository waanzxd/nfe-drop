# NFE-DROP
## Stack

[![Go](https://img.shields.io/badge/Go-1.23+-00ADD8?logo=go&logoColor=white)]()
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-DB-4169E1?logo=postgresql&logoColor=white)]()
[![Docker](https://img.shields.io/badge/Docker-Container-2496ED?logo=docker&logoColor=white)]()
[![Docker Compose](https://img.shields.io/badge/Docker_Compose-Orquestra√ß√£o-2496ED?logo=docker&logoColor=white)]()
[![Ansible](https://img.shields.io/badge/Ansible-Automa√ß√£o-EE0000?logo=ansible&logoColor=white)]()
[![Linux](https://img.shields.io/badge/Linux-Host-FCC624?logo=linux&logoColor=black)]()
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-DB-4169E1?logo=postgresql&logoColor=white)]()
[![Redis](https://img.shields.io/badge/Redis-Cache-DC382D?logo=redis&logoColor=white)]()
[![RabbitMQ](https://img.shields.io/badge/RabbitMQ-Fila-FF6600?logo=rabbitmq&logoColor=white)]()
[![Prometheus](https://img.shields.io/badge/Prometheus-M√©tricas-E6522C?logo=prometheus&logoColor=white)]()
[![Grafana](https://img.shields.io/badge/Grafana-Dashboards-F46800?logo=grafana&logoColor=white)]()
[![Graylog](https://img.shields.io/badge/Graylog-Logs-FF3633?logo=graylog&logoColor=white)]()
[![Wazuh](https://img.shields.io/badge/Wazuh-SIEM-025E8C?logo=wazuh&logoColor=white)]()
[![Git](https://img.shields.io/badge/Git-Controle_de_Vers√£o-F05032?logo=git&logoColor=white)]()
[![GitHub](https://img.shields.io/badge/GitHub-Repo-181717?logo=github&logoColor=white)]()
![MongoDB](https://img.shields.io/badge/MongoDB-6.x-47A248?logo=mongodb&logoColor=white)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-8.x-005571?logo=elasticsearch&logoColor=white)
![OpenSearch](https://img.shields.io/badge/OpenSearch-2.x-005EB8?logo=opensearch&logoColor=white)


<img src="nfe-drop.png" alt="Golang" width="200" />

## Objetivo do Projeto:
- O **nfe-drop** √© um motor de ingest√£o de NF-e, preparado para grandes volumes, que valida, parseia, enfileira, processa e persiste cada nota com logs estruturados e m√©tricas exportadas, pronto para rodar em produ√ß√£o com monitoramento completo
- Monitora pastas (incoming/, processing/, ZIP e XML) usando watcher em **Go**.
- Consegue receber lotes gigantes de arquivos e ir empilhando na fila e processando tudo muito rapido.

### Fluxo de alto n√≠vel

```mermaid
flowchart LR
  subgraph Ingest
    A["Linux inotify / fsnotify watcher"] --> B["incoming/"]
    B --> C["processing/"]
  end

  C -->|job JSON| Q["RabbitMQ nfe-drop-jobs"]
  Q --> WK["nfe-drop-worker - pool de workers"]

  WK -->|parse XML + valida XSD| P["PostgreSQL (nfe, itens, duplicatas, pagamentos, xml)"]
  WK -->|logs JSON| L["Graylog / Filebeat"]
  WK -->|m√©tricas| M["Prometheus ‚Üí Grafana"]

  H["Hosts / agentes"] --> Z["Wazuh"]
  Z --> L
```

Pipeline de processamento de NF-e em **Go**, com:

- monitoramento de diret√≥rio via **inotify** (`fsnotify`)
- valida√ß√£o de XML com **XSD da Sefaz** (libxml2/Go)
- **fila RabbitMQ** + **workers paralelos** em Go
- persist√™ncia em **PostgreSQL**
- **logs estruturados em JSON**
- m√©tricas expostas para **Prometheus / Grafana**
- integra√ß√£o preparada para **Graylog** e **Wazuh**
- provisionamento completo via **Ansible**

Focado em **alto throughput**, robustez e observabilidade. O sistema esta preparado para consumir grandes volumes de NFE.

---

## 1. Vis√£o Geral da Arquitetura

Componentes:

- **Watcher**  
  Servi√ßo systemd em Go que monitora a pasta `incoming/` via fsnotify/inotify:
  - move arquivos v√°lidos para `processing/`
  - descarta qualquer arquivo que nao seja .zip/.xml e lixo (ex.: `Zone.Identifier`) em `ignored/`
  - publica jobs em **RabbitMQ** (tipo `xml` ou `zip`)

- **Worker**  
  Servi√ßo systemd em Go que:
  - consome jobs do RabbitMQ (`nfe-drop-jobs`)
  - valida XML com XSD da **Sefaz**
  - faz parse completo dos campos relevantes (cabe√ßalho, itens, duplicatas, pagamentos)
  - persiste no **PostgreSQL**
  - move o arquivo para `processed/` ou `failed/`
  - emite m√©tricas para Prometheus e logs JSON (prontos pra Graylog / Wazuh)

- **Infra de apoio**
  - **RabbitMQ** (fila de jobs, com DLX configurado)
  - **Redis** (j√° previsto; hoje n√£o √© obrigat√≥rio no fluxo principal)
  - **PostgreSQL** (banco da aplica√ß√£o + backup di√°rio)
  - **Prometheus + Grafana** (observabilidade)
  - **Graylog** (central de logs)
  - **Wazuh** (SIEM / seguran√ßa, via docker-compose oficial)

- **Automa√ß√£o**
  - **Ansible** provisiona tudo: Go, Postgres + DB + migrations, RabbitMQ (docker), Redis, systemd services, observabilidade e Wazuh.

---

## 2. Tecnologias Principais

- **Linguagem: Go**
- **Watcher / Worker:**
  - `github.com/fsnotify/fsnotify` ‚Äì inotify para monitorar diret√≥rios
  - `github.com/lestrrat-go/libxml2` + `github.com/terminalstatic/go-xsd-validate` ‚Äì valida√ß√£o XSD
  - `encoding/xml` ‚Äì parse nativo de XML
  - PostgreSQL via `github.com/jackc/pgx/v5/stdlib`
  - Logging estruturado em JSON (ex.: `log/slog` / logger custom estruturado)
- **Fila:**
  - **RabbitMQ** via `github.com/rabbitmq/amqp091-go`
- **M√©tricas:**
  - `github.com/prometheus/client_golang/prometheus/promhttp`
- **Infra:**
  - **PostgreSQL** nativo
  - **Redis** nativo (reservado para cache/fila futura)
  - **Wazuh** (single-node) via docker-compose oficial
  - **Graylog + OpenSearch + Mongo** via docker-compose
  - **Prometheus + Grafana** via docker-compose
- **Automa√ß√£o / DevOps:**
  - **Ansible** (playbook `ansible/site.yml` + roles dedicadas)
  - **systemd** (services gerados dinamicamente via templates)

---

## 3. Modelo de Dados (PostgreSQL)

### Tabelas principais otimizadas

- `nfe` ‚Äì cabe√ßalho da NF-e
- `nfe_xml` ‚Äì XML bruto + representa√ß√£o JSON
- `nfe_item` ‚Äì itens da nota
- `nfe_duplicatas` ‚Äì duplicatas (cobranca)
- `nfe_pagamentos` ‚Äì formas de pagamento

### Diagrama simplificado

```mermaid
erDiagram
    NFE {
        BIGSERIAL id PK
        CHAR(44)  chave_acesso  "√∫nica"
        CHAR(64)  hash_integridade "SHA-256 do XML"
        SMALLINT  modelo
        INTEGER   serie
        INTEGER   numero
        TIMESTAMP emissao
        SMALLINT  tipo_operacao
        SMALLINT  tipo_ambiente
        VARCHAR   natureza_operacao
        VARCHAR   protocolo_autorizacao
        TIMESTAMP data_autorizacao
        SMALLINT  codigo_status
        CHAR(14)  emitente_cnpj
        VARCHAR   emitente_razao
        CHAR(14)  dest_cnpj_cpf
        VARCHAR   dest_razao
        NUMERIC   valor_total_nota
        NUMERIC   valor_produtos
        NUMERIC   valor_desconto
        NUMERIC   valor_icms
        NUMERIC   valor_ipi
        NUMERIC   valor_pis
        NUMERIC   valor_cofins
        NUMERIC   valor_ii
        NUMERIC   valor_frete
        NUMERIC   valor_seguro
        SMALLINT  modalidade_frete
        TIMESTAMP created_at
        TIMESTAMP updated_at
    }

    NFE_XML {
        BIGINT  nfe_id PK,FK
        TEXT    xml_raw
        JSONB   xml_json
        TIMESTAMP created_at
        TIMESTAMP updated_at
    }

    NFE_ITEM {
        BIGSERIAL id PK
        BIGINT  nfe_id FK
        INTEGER n_item
        VARCHAR codigo
        VARCHAR codigo_ean
        VARCHAR descricao
        CHAR(8) ncm
        CHAR(4) cfop
        VARCHAR unidade
        NUMERIC quantidade
        NUMERIC valor_unit
        NUMERIC valor_total_bruto
        NUMERIC valor_frete
        NUMERIC valor_seguro
        NUMERIC valor_desconto
        NUMERIC valor_outros
        SMALLINT ind_total
        NUMERIC base_calculo_icms
        NUMERIC valor_icms
        NUMERIC base_calculo_icms_st
        NUMERIC valor_icms_st
        NUMERIC valor_ipi
        NUMERIC valor_pis
        NUMERIC valor_cofins
    }

    NFE_DUPLICATAS {
        BIGSERIAL id PK
        BIGINT nfe_id FK
        VARCHAR numero_duplicata
        DATE    data_vencimento
        NUMERIC valor_duplicata
    }

    NFE_PAGAMENTOS {
        BIGSERIAL id PK
        BIGINT nfe_id FK
        SMALLINT indicador_pagamento
        VARCHAR  meio_pagamento
        NUMERIC  valor_pagamento
        CHAR(14) cnpj_credenciadora
        CHAR(2)  bandeira_cartao
        VARCHAR  codigo_autorizacao
    }

    NFE ||--|{ NFE_XML        : "1:1 XML"
    NFE ||--|{ NFE_ITEM       : "1:N Itens"
    NFE ||--|{ NFE_DUPLICATAS : "1:N Duplicatas"
    NFE ||--|{ NFE_PAGAMENTOS : "1:N Pagamentos"
```

---

## 4. Pr√©-requisitos

No host (Ubuntu/Debian-like):

- `sudo` configurado
- Python 3.x (para Ansible)
- Acesso √† internet (para baixar depend√™ncias, docker images, etc.)

Tudo o resto o **Ansible** cuida:

- Go
- PostgreSQL (servidor, DB, usu√°rio, tabelas)
- Redis
- Docker + Docker Compose plugin
- RabbitMQ (via Docker)
- Grafana + Prometheus (via Docker)
- Graylog + OpenSearch + Mongo (via Docker)
- Wazuh (single-node, via Docker)
- systemd units para watcher / worker
- üíæüõ°Ô∏è backup di√°rio do Postgres

---

## 5. Instala√ß√£o R√°pida (modo ‚Äú1 comando‚Äù)

1. Entre na pasta do projeto:

```bash
cd ~/golang/nfe-drop/ansible
```

2. Teste a conex√£o Ansible:

```bash
ansible -i inventory.ini local -m ping
```

3. Rode o playbook (vai pedir senha do sudo):

```bash
ansible-playbook -i inventory.ini site.yml -K
```

Esse playbook vai:

- instalar Go (caso n√£o tenha)
- instalar e configurar PostgreSQL
  - criar DB `nfe_drop` se n√£o existir
  - rodar migrations (tabelas nfe, nfe_item, etc.)
- instalar Docker + Compose plugin
- subir RabbitMQ em Docker
- instalar Redis
- compilar o projeto Go (watcher + worker)
- instalar systemd units do `nfe-drop-watcher` e `nfe-drop-worker`
- garantir que os servi√ßos estejam **habilitados e rodando**
- subir stack de observabilidade (Prometheus, Grafana, Graylog)
- subir Wazuh single-node com certificados gerados

---

## 6. Diret√≥rios Importantes

Por padr√£o, o Ansible usa:

- **C√≥digo-fonte / build:**

  ```bash
  /home/<user>/golang/nfe-drop
  ```

- **Diret√≥rio de runtime / servi√ßos (pastas da aplica√ß√£o, stacks docker):**

  ```bash
  /opt/nfe-drop-services
  ```

Dentro de `/opt/nfe-drop-services`:

- `incoming/` ‚Äì onde o usu√°rio dropa XML/ZIP
- `processing/` ‚Äì arquivos em processamento
- `processed/` ‚Äì arquivos j√° processados com sucesso
- `failed/` ‚Äì arquivos que falharam (XML inv√°lido, duplicidade, erro de DB, etc.)
- `ignored/` ‚Äì arquivos que nao sao xml e **Zone.Identifier** √© sempre apagado, problema comum em **WSL** 
- `tmp/` ‚Äì tempor√°rios (ex.: extra√ß√£o de ZIP)
- `deploy/` ‚Äì docker-compose de Rabbit, Grafana, Prometheus, Graylog, Wazuh, etc.

---

## 7. Servi√ßos e Portas

### Aplica√ß√£o Go

- `nfe-drop-watcher.service`
  - systemd
  - monitora `incoming/`
- `nfe-drop-worker.service`
  - systemd
  - consome fila e processa os XML/ZIP

Portas de m√©tricas (Prometheus scrape):

- Watcher: `:9100` ‚Üí `http://localhost:9100/metrics`
- Worker: `:9101` ‚Üí `http://localhost:9101/metrics`

### RabbitMQ

- Porta AMQP: `5672`
- Management UI: `15672` ‚Üí `http://localhost:15672`  
  - usu√°rio padr√£o (no compose): `guest` / `guest` (ou ajustado via env/role)

### Redis

- Porta padr√£o: `6379`

### Prometheus

- `http://localhost:9090`

### Grafana

- `http://localhost:3000`  
  (usu√°rio / senha padr√£o: `admin` / `admin` ‚Äì troque na primeira vez)

### Graylog

- Web UI (via compose observability):  
  `http://localhost:9000`  
  (usu√°rio padr√£o geralmente `admin` ‚Äî senha definida via env no compose)

### Wazuh

- Dashboard:
  - **HTTPS** em: `https://localhost:5601` (ajustado via Ansible)
- Indexer: `http://localhost:9200` (n√£o √© pra acesso direto em produ√ß√£o)
- Manager:
  - Porta API: `55000`
  - Syslog/agents: `1514-1516`, etc.

---

## 8. Fluxo de Processamento (Detalhado)

1. **Upload / Drop de arquivos**
   - Voc√™ copia arquivos `.xml` ou `.zip` para `incoming/`
   - Qualquer lixo √© detectado e movido para `ignored/`

2. **Watcher**
   - V√™ o arquivo novo via inotify
   - Move para `processing/`
   - Monta um job JSON:
     - tipo (`xml` ou `zip`)
     - caminho completo do arquivo
   - Publica na fila RabbitMQ (`nfe-drop-jobs`)

3. **Worker**
   - Consome o job da fila
   - Se for ZIP:
     - extrai todos os XML para `tmp/<zipname>/`
     - processa cada XML individualmente
     - voc√™ pode ter cen√°rio:
       - algumas notas novas ‚Üí sucesso
       - algumas duplicadas ‚Üí inser√ß√£o ignorada apenas para aquelas
     - o zip √© movido para `processed/` **se pelo menos uma nota foi processada com sucesso** e nenhuma falha cr√≠tica
   - Se for XML:
     - valida contra XSD da Sefaz
     - faz parse completo:
       - cabe√ßalho (nfe)
       - itens (nfe_item)
       - duplicatas (nfe_duplicatas)
       - pagamentos (nfe_pagamentos)
       - XML bruto em `nfe_xml`
     - calcula `hash_integridade` (ex. SHA-256 do XML) para garantir unicidade
     - insere tudo num **√∫nico fluxo transacional** no PostgreSQL
     - em caso de `duplicate key` (chave_acesso):
       - trata a NF-e como j√° processada
       - loga evento e envia para m√©tricas
   - Ao final:
     - sucesso ‚Üí move arquivo para `processed/`
     - falha validada ‚Üí `failed/` (com logs indicando o motivo)

4. **Observabilidade**
   - Cada NF-e gera:
     - incremento em `nfe_processed_total{status="success|failed|duplicate", source="xml|zip"}`
     - dura√ß√£o em `nfe_process_duration_seconds`
   - Logs estruturados permitem:
     - filtros no Graylog/Wazuh por `chave_acesso`, `emitente_cnpj`, tipo de erro, etc.

---

## 9. Ansible: o que ele faz por voc√™

Playbook principal: `ansible/site.yml`

Roles (resumo):

- `go`
  - instala Go no host (se n√£o tiver)
- `nfe-drop-db`
  - instala PostgreSQL
  - cria banco `nfe_drop`
  - roda migrations via bin√°rio `nfe-drop-migrator` ou `go run`
- `postgres-backup`
  - configura backup di√°rio (cron) com `pg_dump` do `nfe_drop`
- `docker-engine`
  - instala `docker.io` + plugin `docker compose`
- `redis-server`
  - instala Redis nativo
- `nfe-drop-rabbitmq-docker`
  - sobe RabbitMQ via docker-compose (com env configurado)
- `nfe-drop-app`
  - garante diret√≥rios `incoming/`, `processing/`, `processed/`, `failed/`, `ignored/`, `tmp/`
  - compila watcher e worker (`go build`)
  - instala systemd units com usu√°rio din√¢mico (`login_user`)
  - habilita e inicia `nfe-drop-watcher` e `nfe-drop-worker`
- `nfe-drop-observability`
  - sobe stack Prometheus + Grafana (docker-compose)
  - adiciona targets para `:9100` e `:9101`
- `nfe-drop-graylog`
  - sobe Graylog + Mongo + OpenSearch em docker-compose
- `nfe-drop-wazuh`
  - clona `wazuh-docker` na tag est√°vel `v4.8.0`
  - ajusta `docker-compose.yml` da topologia `single-node`
  - gera certificados via `generate-indexer-certs.yml`
  - sobe stack e exibe instru√ß√µes de acesso

---

## 10. Como rodar localmente (sem Ansible, modo dev)

Se quiser debugar s√≥ o Go, ignorando Ansible:

1. Ajuste o `.env` na raiz:

```env
# DB
NFE_DROP_DB_HOST=localhost
NFE_DROP_DB_PORT=5432
NFE_DROP_DB_USER=...
NFE_DROP_DB_PASSWORD=...
NFE_DROP_DB_NAME=nfe_drop
NFE_DROP_DB_SSLMODE=disable

# RabbitMQ
NFE_DROP_RABBITMQ_URL=amqp://guest:guest@localhost:5672/

# Base de diret√≥rios (opcional)
NFE_DROP_BASE_DIR=/home/<user>/nfe-drop

# Logs / m√©tricas
NFE_DROP_LOG_LEVEL=info
NFE_DROP_WATCHER_METRICS_ADDR=:9100
NFE_DROP_WORKER_METRICS_ADDR=:9101
```

2. Rode migrations:

```bash
go run ./cmd/nfe-drop-migrator
# ou
go run ./cmd/nfe-drop-migrator --force   # para recriar banco do zero
```

3. Suba o watcher e o worker:

```bash
go run ./cmd/nfe-drop-watcher
go run ./cmd/nfe-drop-worker
```

---

## 11. Comandos √∫teis

### Systemd

```bash
# status
systemctl status nfe-drop-watcher
systemctl status nfe-drop-worker

# logs
journalctl -u nfe-drop-watcher -f
journalctl -u nfe-drop-worker -f

# restart
sudo systemctl restart nfe-drop-watcher
sudo systemctl restart nfe-drop-worker
```

### Docker

```bash
# RabbitMQ
docker ps | grep rabbit
docker logs -f nfe-drop-rabbitmq

# Observabilidade
docker ps | egrep "grafana|prometheus|graylog|opensearch|mongo"

# Wazuh
cd /opt/nfe-drop-services/deploy/wazuh-docker/single-node
docker compose ps
docker logs -f single-node-wazuh.indexer-1
docker logs -f single-node-wazuh.dashboard-1
```

### Ansible

```bash
cd ansible

# Executar playbook completo
ansible-playbook -i inventory.ini site.yml -K
```

---

## 12. Roadmap / Ideias Futuras

- Enriquecimento de NF-e (ex.: cache de NCM, CFOP, CST em Redis)
- Exposi√ß√£o de API REST para consulta das NF-e (Go ou PHP/Laravel separado)
- UI para monitoramento da fila e reprocessamento manual
- Feature flags para:
  - modo somente-valida√ß√£o (sem persistir)
- Exporta√ß√£o de m√©tricas espec√≠ficas por:
  - CNPJ emitente
  - c√≥digo de status da Sefaz
  - volume por per√≠odo (hora/dia/semana)

---

- **Go idiom√°tico**, com separa√ß√£o clara de responsabilidades:
  - `internal/watcher`
  - `internal/worker`
  - `internal/nfe` (parse e valida√ß√£o)
  - `internal/storage` (persist√™ncia)
  - `internal/config` (config centralizada)
- Integra√ß√£o com **RabbitMQ**, **PostgreSQL**, **Redis**
- Uso de **XSD real da Sefaz** para valida√ß√£o forte de NF-e
- **infra as code** com **Ansible**
- Observabilidade completa:
  - **Prometheus/Grafana** (m√©tricas)
  - **Graylog** (logs estruturados)
  - **Wazuh** (seguran√ßa e SIEM)
- Provisionamento automatizado:  
  `ansible-playbook -i inventory.ini site.yml -K`

---
